{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6.1卷积神经网络的原则\n",
    "1.平移不变性(translation invariance)\n",
    "    表示不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的翻译，即“平移不变性”\n",
    "2.局部性(locality)\n",
    "    神经网络的前面几层应该只探索输入图像中的局部区域，而不过多在意图像中相隔较远区域的关系，即“局部性”原则\n",
    "\n",
    "# 6.2图像卷积\n",
    "## 6.2.1互相关运算\n",
    "实际上，卷积层进行的是互相关运算，而不是卷积运算\n",
    "\n",
    "对互相关运算简化处理，忽略通道（第三维）的情况，我们关注输入的图像大小为n_h和n_w，卷积核的大小k_h和k_w，则输出大小为:\n",
    "\n",
    "(n_h-k_h+1)*(n_w-k_w+1)\n",
    "\n",
    "注意到，输出的维度会比输入的维度小，那么如果叠加多个像上面的卷积层，输出的维度会逐渐缩小至消失，因此会在图像边缘加入“填充”(padding)来保持输出大小不变。\n",
    "\n",
    " 为代码实现（主要用到corr2d函数）"
   ],
   "id": "b7baf1fcfbc195b8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T01:26:59.246126Z",
     "start_time": "2025-03-03T01:26:45.912818Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "def corr2d(X,K): #@save\n",
    "    '''二维互相关运算'''\n",
    "    h,w = K.shape      #卷积核的高和宽\n",
    "    Y = torch.zeros((X.shape[0]-h+1,X.shape[1]-w+1))  #初始化输出的张量\n",
    "    for i in range(Y.shape[0]):    # 双循环计算输出的张量中每个元素\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0.0,1.0,2.0],[3.0,4.0,5.0],[6.0,7.0,8.0]])\n",
    "K = torch.tensor([[0.1,1.0],[2.0,3.0]])\n",
    "corr = corr2d(X,K)\n",
    "print(corr)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19.0000, 25.1000],\n",
      "        [37.3000, 43.4000]])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "注意到上述代码实际运行时间约13秒，而输入与核的大小均很小，因此双循环的方式实现corr2d时间复杂度高，向量化计算会更快\n",
   "id": "74c0cceae7ad3bd7"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "## 6.2.2卷积层\n",
    "卷积层对输入和卷积核进行互相关运算，再加上标量偏置后产生输出。\n",
    "\n",
    "卷积层中两个被训练的参数是：（1）卷积核；（2）标量偏置\n",
    "\n",
    "下面代码基于定义的corr2d函数实现二维卷积层"
   ],
   "id": "4890cae21b15c19a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super().__init()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bais = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight) + self.bais"
   ],
   "id": "ee7e48683f49d20f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.2.3图像中目标的边缘检测\n",
    "卷积层的简单应用：通过找到像素变化的位置来检测图像中不同颜色的边缘\n",
    "\n",
    "1.构造一个6像素x8像素的黑白图像，中间4列为黑色，其余像素为白色"
   ],
   "id": "fdb857ada83aaf05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T01:53:32.372747Z",
     "start_time": "2025-03-03T01:53:32.369331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.ones((6,8))\n",
    "X[:,2:6] = 0\n",
    "print(X)"
   ],
   "id": "51681d587271ba8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.]])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2.构造高度为1，宽度为2的卷积核K。互相关运算时，如果水平相邻的两元素相同，则输出为0，否则输出为非0",
   "id": "894aa6dff39b908b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T01:59:03.561281Z",
     "start_time": "2025-03-03T01:59:03.557196Z"
    }
   },
   "cell_type": "code",
   "source": "K = torch.tensor([[1.0,-1.0]])",
   "id": "bf9d272ed8598261",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.执行互相关运算",
   "id": "e497059801201e20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T01:59:05.243892Z",
     "start_time": "2025-03-03T01:59:05.240331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y = corr2d(X,K)\n",
    "print(Y)"
   ],
   "id": "eec072cc173a9fe2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "将二维图像转置，进行互相关运算",
   "id": "611141c46033c014"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T01:59:54.485431Z",
     "start_time": "2025-03-03T01:59:54.476680Z"
    }
   },
   "cell_type": "code",
   "source": "corr2d(X.t(),K)",
   "id": "8e33a79e89e6c582",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "这个卷积核K只能检测垂直边缘，无法检测水平边缘",
   "id": "e92de2a26652596a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.2.4卷积核\n",
    "学习由X生成Y的卷积核，暂且忽略偏置项"
   ],
   "id": "7f11f704338b2dd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T02:12:08.491950Z",
     "start_time": "2025-03-03T02:12:08.444703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 构造一个二维卷积层，它具有1个输出通道和形状为(1,2)的卷积核\n",
    "conv2d = nn.Conv2d(1,1,kernel_size=(1,2),bias=False)\n",
    "\n",
    "# 这个二维卷积层使用四维输入和输出格式(批量大小、通道、高度、宽度)\n",
    "X=X.reshape((1,1,6,8))\n",
    "Y=Y.reshape((1,1,6,7))\n",
    "lr = 3e-2 #学习率\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y)**2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    # 迭代卷积核\n",
    "    conv2d.weight.data[:] -= lr*conv2d.weight.grad\n",
    "    if (i+1) % 2 ==0:\n",
    "        print(f'epoch {i+1},loss {l.sum():.3f}')"
   ],
   "id": "6a3fccc73bea5bf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2,loss 7.283\n",
      "epoch 4,loss 2.464\n",
      "epoch 6,loss 0.922\n",
      "epoch 8,loss 0.363\n",
      "epoch 10,loss 0.146\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "解释一下这里的conv2d.zero_grad()的作用是将卷积层conv2d的所有参数的梯度设置为0，原因是当调用backward()方法进行反向传播计算的时候，梯度值会累加到参数的.grad属性中，会与之前得到的梯度相加，所以需要置0",
   "id": "b84bd5548365c4b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T02:19:51.824865Z",
     "start_time": "2025-03-03T02:19:51.819494Z"
    }
   },
   "cell_type": "code",
   "source": "conv2d.weight.data.reshape((1,2))",
   "id": "63728a4aa65cbe62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9531, -1.0316]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.2.5互相关和卷积\n",
    "由于卷积核是从数据中学习的，因此无论执行严格的卷积运算还是互相关运算，卷积层的输出均不受影响。\n",
    "\n",
    "为了与文献标准术语保持一致，我们将“互相关运算”称为卷积运算；对于卷积核张量上的权重，我们称其为元素\n",
    "\n",
    "## 6.2.6特征映射和感受野\n",
    "卷积层有时成为特征映射(feature map)，可以被视为一个输入映射到下一层的空间维度的转换器\n",
    "\n",
    "在CNN中，对于某一层的任意元素x，其感受野(receptive field)指在向前传播期间可能影响到x计算的所有元素（来自所有之前层）\n",
    "\n",
    "感受野的图解在Ob/深度学习/L7/P46"
   ],
   "id": "a2062ade7fada508"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6.3填充和步幅\n",
    "## 6.3.1填充\n",
    "在应用多层卷积时，我们尝尝丢失边缘像素。为了解决这个问题，我们采用填充(padding)的方法：在图像的边缘填充元素（通常为0）\n",
    "\n",
    "如果添加p_h行填充和p_w列填充，输出形状变为：\n",
    "\n",
    "(n_h-k_h+p_h+1)*(n_w-k_w+p_w+1)\n",
    "\n",
    "很多情况下，会设置p_h=k_h-1，p_w=k_w-1来使输入和输出具有相同的高度和宽度\n"
   ],
   "id": "5d827a5ac92c1884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T02:46:23.571769Z",
     "start_time": "2025-03-03T02:46:23.555431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 为方便起见，我们定义一个计算卷积的函数\n",
    "# 此函数初始化卷积层权重，并对输入和输出扩大和缩减相应倍数\n",
    "def comp_conv2d(conv2d,X):\n",
    "    # 这里的(1,1)表示批量大小和通道数都是1\n",
    "    X = X.reshape((1,1)+X.shape) # 这里的加号实现的拼接功能\n",
    "    Y = conv2d(X)\n",
    "    # 省略前两个维度：批量大小和通道\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 注意，这里每侧边都填充了1行或1列，因此总共添加了2行或2列\n",
    "conv2d = nn.Conv2d(1,1,kernel_size=3,padding=1) # 这里kernel_size一般设置为元组，如果是标量的话说明是正方形\n",
    "X = torch.rand(size=(8,8))\n",
    "comp_conv2d(conv2d,X).shape"
   ],
   "id": "1fffe69675dbcedf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T03:02:55.526029Z",
     "start_time": "2025-03-03T03:02:55.519758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=(5,3),padding=(2,1)) # 高度和宽度两侧边的填充分别为2,1\n",
    "comp_conv2d(conv2d,X).shape"
   ],
   "id": "4f0d406577dd2d1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.3.2步幅\n",
    "有时候为了高效计算或缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素\n",
    "\n",
    "每次滑动元素的数量称为步幅\n",
    "\n",
    "当垂直步幅为s_h，水平步幅为s_w时，输出形状为：\n",
    "\n",
    "[(n_h-k_h+p_h+s_h)/s_h]x[(n_w-k_w+p_w+s_w)/s_w]\n",
    "\n",
    "可以设置p_h=k_h-1，p_w=k_w-1，输出形状简化为：[(n_h+s_h-1)/s_h]x[(n_w+s_w-1)/s_w]"
   ],
   "id": "d9a17af2355ac548"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T05:43:15.904326Z",
     "start_time": "2025-03-03T05:43:15.895347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=3,padding=1,stride=2)  # 构建二维卷积层\n",
    "comp_conv2d(conv2d,X).shape"
   ],
   "id": "c307040126434d61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T05:46:03.230319Z",
     "start_time": "2025-03-03T05:46:03.217337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=(3,5),padding=(0,1),stride=(3,4))\n",
    "comp_conv2d(conv2d,X).shape"
   ],
   "id": "9883a114bfa5cd46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "实际使用中很少使用不一致的步幅或填充",
   "id": "c70fe8f1b5720efa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6.4多输入多输出通道\n",
    "对于RGB输入图像而言，具有3xhxw的形状，这个大小为3的轴称为通道(channel)维度\n",
    "## 6.4.1多输入通道\n",
    "当输入包含多个通道时，需要构造一个具有与输入数据相同输入通道数的卷积核，以便于输入数据进行互相关运算。\n",
    "\n",
    "所谓多输入通道互相关运算，就是对每个通道执行互相关操作"
   ],
   "id": "90ed0740bad19d8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T06:03:07.275061Z",
     "start_time": "2025-03-03T06:03:07.257946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "def corr2d_multi_in(X,K):\n",
    "    # 先遍历X和K的第0个维度（通道维度），再把它们加到一起\n",
    "    return sum(d2l.corr2d(x,k) for x,k in zip(X,K))"
   ],
   "id": "4131e01f83f85f38",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "zip是Python的内置函数，用于将多个可迭代对象（如列表、元组等）中的元素一一对应地合成元素\n",
    "\n",
    "在上述代码中，zip(X,K)会将X和K中对应通道的数据和卷积核合成一个元组，如(X[0],K[0])、(X[1],K[1])等，这样可以对每个通道分别进行卷积操作"
   ],
   "id": "f87d093673f36cf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T06:24:50.369847Z",
     "start_time": "2025-03-03T06:24:50.350035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.tensor([[[0.0,1.0,2.0],[3.0,4.0,5.0],[6.0,7.0,8.0]],\n",
    "                  [[1.0,2.0,3.0],[4.0,5.0,6.0],[7.0,8.0,9.0]]])\n",
    "K = torch.tensor([[[0.0,1.0],[2.0,3.0]],[[1.0,2.0],[3.0,4.0]]])\n",
    "corr2d_multi_in(X,K)"
   ],
   "id": "6edacd4d03b0f1ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.4.2多输出通道\n",
    "我们可以将每个通道看作对不同特征的响应，每个通道不是独立学习的，而是为了共同使用而优化的。因此，多输出通道并不仅是学习多个单通道的检测器\n",
    "\n",
    "输入通道数：c_i\n",
    "\n",
    "输出通道数：c_0\n",
    "\n",
    "卷积核形状：c_0xc_ixk_hxk_w"
   ],
   "id": "a3dc53a78b4441e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T06:23:59.503478Z",
     "start_time": "2025-03-03T06:23:59.499163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def corr2d_multi_in_out(X,K):\n",
    "    # 迭代K的第0个维度，每次都对输入X执行互相关运算\n",
    "    # 最后将所有结果都叠加在一起\n",
    "    return torch.stack([corr2d_multi_in(X,k) for k in K],0)"
   ],
   "id": "8570a32680c9bd44",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "[corr2d_multi_in(X, k) for k in K]是一个列表推导式，对K中的每个元素执行corr2d_multi_in函数，最终得到一个包含多个卷积结果的列表\n",
    "\n",
    "torch.stack是PyTorch中的一个函数，用于沿着指定的维度将多个张量堆叠在一起，0表示沿着第0个维度进行堆叠"
   ],
   "id": "c8c1c9df76f108c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T06:26:23.962288Z",
     "start_time": "2025-03-03T06:26:23.943777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "K = torch.stack((K,K+1,K+2),0)\n",
    "K.shape"
   ],
   "id": "a1dddbc34df7a169",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T06:26:35.526160Z",
     "start_time": "2025-03-03T06:26:35.508090Z"
    }
   },
   "cell_type": "code",
   "source": "corr2d_multi_in_out(X,K)",
   "id": "d49c192b9f949962",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.4.31x1卷积层\n",
    "卷积的本质是有效提取相邻像素间的相关特征，但是1x1卷积没有这个作用\n",
    "\n",
    "1x1卷积的唯一计算发生在通道上"
   ],
   "id": "8781852f32c8630e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T06:49:50.373197Z",
     "start_time": "2025-03-03T06:49:50.363584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def corr2d_multi_in_out_1x1(X,K):\n",
    "    c_i,h,w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i,h*w))\n",
    "    K = K.reshape((c_o,c_i))\n",
    "    # 全连接层中的矩阵乘法\n",
    "    Y = torch.matmul(K,X)\n",
    "    return Y.reshape((c_o,h,w))"
   ],
   "id": "29d801641de28992",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T06:51:10.126760Z",
     "start_time": "2025-03-03T06:51:10.100363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.normal(0,1,(3,3,3))\n",
    "K = torch.normal(0,1,(2,3,1,1))\n",
    "Y1 = corr2d_multi_in_out_1x1(X,K)\n",
    "Y2 = corr2d_multi_in_out(X,K)\n",
    "assert float(torch.abs(Y1-Y2).sum())<1e-6"
   ],
   "id": "c9c64005f951ddf7",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6.5汇聚层\n",
    "通常处理图像时，我们希望逐渐降低隐藏层表示的空间分辨率、聚合信息，这样随着神经网络中层数的增加，每个神经元对其敏感的感受野就越大\n",
    "\n",
    "汇聚层(pooling layer)具有双重目的：1.降低卷积层对位置的敏感性；2.降低对空间降采样表示的敏感性\n",
    "\n",
    "## 6.5.1最大汇聚和平均汇聚\n",
    "最大汇聚(maximum pooling)：计算汇聚窗口中所有元素的最大值；\n",
    "平均汇聚(average pooling)：计算汇聚窗口中所有元素的平均值"
   ],
   "id": "1d9c48ce380f606a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T09:51:53.974178Z",
     "start_time": "2025-03-03T09:51:53.958850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def pool2d(X,pool_size,mode='max'):\n",
    "    p_h,p_w =pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1,X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i,j] = X[i:i+p_h,j:j+p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i,j] = X[i:i+p_h,j:j+j+p_w].mean()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0.0,1.0,2.0],[3.0,4.0,5.0],[6.0,7.0,8.0]])\n",
    "pool2d(X,(2,2),'avg')"
   ],
   "id": "815b80b201004ced",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.5.2填充和步幅\n",
    "我们可以通过填充和步幅获得所需要的输出形状"
   ],
   "id": "b2a011d9c3a5ff74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T09:55:10.343883Z",
     "start_time": "2025-03-03T09:55:10.330145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.arange(16,dtype=torch.float32).reshape((1,1,4,4))\n",
    "X"
   ],
   "id": "fb7bb00be9695ecc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T10:46:32.428896Z",
     "start_time": "2025-03-03T10:46:32.399926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(X)"
   ],
   "id": "2950bda2b0982a8c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T10:47:33.239548Z",
     "start_time": "2025-03-03T10:47:33.226323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pool2d = nn.MaxPool2d(3,padding=1,stride=2)\n",
    "pool2d(X)"
   ],
   "id": "93502b954109e6c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "默认情况下，深度学习框架中的步幅与汇聚窗口的大小相同。因此，如果使用形状为(3,3)的汇聚窗口，那么默认情况下，步幅形状为(3,3)",
   "id": "bbcf1d3c5448a2f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T10:50:52.250510Z",
     "start_time": "2025-03-03T10:50:52.237596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pool2d = nn.MaxPool2d((2,3),stride=(2,3),padding=(0,1))\n",
    "pool2d(X)"
   ],
   "id": "610bb6f839212594",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.5.3多个通道\n",
    "在处理多通道输入数据时，汇聚层在每个输入通道上单独运算，而不是像卷积层那样在通道上对输入进行汇总（结合PPT理解一下吧）\n",
    "\n",
    "这意味着汇聚层的输出通道数与输入通道数相同\n",
    "\n",
    "以下代码在通道维度（第一维）连接张量X和X+1，以构建具有2个通道的输入"
   ],
   "id": "fae35672a9b34493"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T10:58:37.213559Z",
     "start_time": "2025-03-03T10:58:37.203208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.cat((X,X+1),1)\n",
    "X"
   ],
   "id": "ee1cd3dcb41ac8aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:01:29.930443Z",
     "start_time": "2025-03-03T11:01:29.916202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pool2d = nn.MaxPool2d(3,padding=1,stride=2)\n",
    "pool2d(X)"
   ],
   "id": "eca76bdf2378b37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "25eaacfd4d6f315f"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-03T13:45:49.173224Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aee69593ba432ebe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T14:31:22.010644Z",
     "start_time": "2025-03-09T14:31:21.999501Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"hello\")",
   "id": "d6f5cc33c68a33cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
